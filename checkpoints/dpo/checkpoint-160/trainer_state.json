{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.8888888888888888,
  "eval_steps": 40,
  "global_step": 160,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05925925925925926,
      "grad_norm": 96.89079284667969,
      "learning_rate": 2.222222222222222e-06,
      "logits/chosen": -0.7654188871383667,
      "logits/rejected": -0.6057721376419067,
      "logps/chosen": -258.34173583984375,
      "logps/rejected": -176.92990112304688,
      "loss": 11.0935,
      "rewards/accuracies": 0.18125000596046448,
      "rewards/chosen": -0.00032258988358080387,
      "rewards/margins": -0.0003845072351396084,
      "rewards/rejected": 6.191730790305883e-05,
      "step": 5
    },
    {
      "epoch": 0.11851851851851852,
      "grad_norm": 97.02216339111328,
      "learning_rate": 4.444444444444444e-06,
      "logits/chosen": -0.8117924928665161,
      "logits/rejected": -0.6615302562713623,
      "logps/chosen": -266.94549560546875,
      "logps/rejected": -191.49656677246094,
      "loss": 10.9156,
      "rewards/accuracies": 0.8374999761581421,
      "rewards/chosen": 0.009768209420144558,
      "rewards/margins": 0.022096386179327965,
      "rewards/rejected": -0.012328176759183407,
      "step": 10
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 79.74129486083984,
      "learning_rate": 4.9921961409251465e-06,
      "logits/chosen": -0.7916385531425476,
      "logits/rejected": -0.6707288026809692,
      "logps/chosen": -271.70050048828125,
      "logps/rejected": -193.11549377441406,
      "loss": 9.5322,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.09196572005748749,
      "rewards/margins": 0.2085351198911667,
      "rewards/rejected": -0.11656942218542099,
      "step": 15
    },
    {
      "epoch": 0.23703703703703705,
      "grad_norm": 65.80855560302734,
      "learning_rate": 4.960576444868992e-06,
      "logits/chosen": -0.8008524179458618,
      "logits/rejected": -0.5987065434455872,
      "logps/chosen": -265.5936584472656,
      "logps/rejected": -181.2204132080078,
      "loss": 7.0527,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.24123528599739075,
      "rewards/margins": 0.6007760167121887,
      "rewards/rejected": -0.35954076051712036,
      "step": 20
    },
    {
      "epoch": 0.2962962962962963,
      "grad_norm": 48.334041595458984,
      "learning_rate": 4.904961286807285e-06,
      "logits/chosen": -0.7620479464530945,
      "logits/rejected": -0.644866943359375,
      "logps/chosen": -240.87057495117188,
      "logps/rejected": -189.88687133789062,
      "loss": 5.2946,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.37673258781433105,
      "rewards/margins": 0.9584611654281616,
      "rewards/rejected": -0.5817285776138306,
      "step": 25
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 36.75368881225586,
      "learning_rate": 4.825893023964886e-06,
      "logits/chosen": -0.8422659039497375,
      "logits/rejected": -0.580078661441803,
      "logps/chosen": -247.2859344482422,
      "logps/rejected": -183.56781005859375,
      "loss": 3.6444,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.5516154170036316,
      "rewards/margins": 1.4216387271881104,
      "rewards/rejected": -0.8700233697891235,
      "step": 30
    },
    {
      "epoch": 0.4148148148148148,
      "grad_norm": 26.45157814025879,
      "learning_rate": 4.724142727486869e-06,
      "logits/chosen": -0.8686424493789673,
      "logits/rejected": -0.6520550847053528,
      "logps/chosen": -253.3555145263672,
      "logps/rejected": -187.85423278808594,
      "loss": 2.5412,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.6724153161048889,
      "rewards/margins": 1.8457515239715576,
      "rewards/rejected": -1.1733362674713135,
      "step": 35
    },
    {
      "epoch": 0.4740740740740741,
      "grad_norm": 20.710147857666016,
      "learning_rate": 4.600702662977611e-06,
      "logits/chosen": -0.8912661671638489,
      "logits/rejected": -0.7451797127723694,
      "logps/chosen": -249.2239990234375,
      "logps/rejected": -194.78855895996094,
      "loss": 1.685,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.802080512046814,
      "rewards/margins": 2.3522396087646484,
      "rewards/rejected": -1.550159215927124,
      "step": 40
    },
    {
      "epoch": 0.4740740740740741,
      "eval_logits/chosen": -0.8981160521507263,
      "eval_logits/rejected": -0.7723817229270935,
      "eval_logps/chosen": -260.88946533203125,
      "eval_logps/rejected": -190.5139617919922,
      "eval_loss": 0.07777953147888184,
      "eval_rewards/accuracies": 1.0,
      "eval_rewards/chosen": 0.8918322920799255,
      "eval_rewards/margins": 2.7202939987182617,
      "eval_rewards/rejected": -1.828461766242981,
      "eval_runtime": 32.7859,
      "eval_samples_per_second": 9.15,
      "eval_steps_per_second": 4.575,
      "step": 40
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 13.37112808227539,
      "learning_rate": 4.456776613958683e-06,
      "logits/chosen": -0.9315444827079773,
      "logits/rejected": -0.7550381422042847,
      "logps/chosen": -249.73800659179688,
      "logps/rejected": -201.34661865234375,
      "loss": 1.1609,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 0.899838924407959,
      "rewards/margins": 2.825627326965332,
      "rewards/rejected": -1.925788164138794,
      "step": 45
    },
    {
      "epoch": 0.5925925925925926,
      "grad_norm": 10.731115341186523,
      "learning_rate": 4.293768142610828e-06,
      "logits/chosen": -0.9489143490791321,
      "logits/rejected": -0.844153106212616,
      "logps/chosen": -259.3544921875,
      "logps/rejected": -214.16162109375,
      "loss": 0.7435,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.0103223323822021,
      "rewards/margins": 3.4259071350097656,
      "rewards/rejected": -2.4155848026275635,
      "step": 50
    },
    {
      "epoch": 0.6518518518518519,
      "grad_norm": 6.3005290031433105,
      "learning_rate": 4.113266902280914e-06,
      "logits/chosen": -1.0882642269134521,
      "logits/rejected": -0.8769086599349976,
      "logps/chosen": -254.28274536132812,
      "logps/rejected": -224.29800415039062,
      "loss": 0.5113,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.1649973392486572,
      "rewards/margins": 4.038952350616455,
      "rewards/rejected": -2.8739545345306396,
      "step": 55
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 6.0862627029418945,
      "learning_rate": 3.917033135233845e-06,
      "logits/chosen": -1.0265920162200928,
      "logits/rejected": -0.9238597750663757,
      "logps/chosen": -261.91900634765625,
      "logps/rejected": -225.0565948486328,
      "loss": 0.2859,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.17914879322052,
      "rewards/margins": 4.682513236999512,
      "rewards/rejected": -3.5033645629882812,
      "step": 60
    },
    {
      "epoch": 0.7703703703703704,
      "grad_norm": 6.697178840637207,
      "learning_rate": 3.7069805068268626e-06,
      "logits/chosen": -1.0275551080703735,
      "logits/rejected": -0.9613431096076965,
      "logps/chosen": -245.458740234375,
      "logps/rejected": -216.4739532470703,
      "loss": 0.2519,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.2638288736343384,
      "rewards/margins": 5.067493438720703,
      "rewards/rejected": -3.8036646842956543,
      "step": 65
    },
    {
      "epoch": 0.8296296296296296,
      "grad_norm": 1.750038743019104,
      "learning_rate": 3.4851574435067925e-06,
      "logits/chosen": -1.104490041732788,
      "logits/rejected": -1.0132689476013184,
      "logps/chosen": -263.65740966796875,
      "logps/rejected": -217.14981079101562,
      "loss": 0.1468,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3643198013305664,
      "rewards/margins": 5.734262466430664,
      "rewards/rejected": -4.369943141937256,
      "step": 70
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 2.8917484283447266,
      "learning_rate": 3.253727156621508e-06,
      "logits/chosen": -1.1916532516479492,
      "logits/rejected": -1.1041431427001953,
      "logps/chosen": -276.9949645996094,
      "logps/rejected": -229.4876251220703,
      "loss": 0.0862,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.3973408937454224,
      "rewards/margins": 6.553485870361328,
      "rewards/rejected": -5.156144142150879,
      "step": 75
    },
    {
      "epoch": 0.9481481481481482,
      "grad_norm": 1.5034825801849365,
      "learning_rate": 3.014946546852746e-06,
      "logits/chosen": -1.2222130298614502,
      "logits/rejected": -1.0756529569625854,
      "logps/chosen": -253.8397979736328,
      "logps/rejected": -232.574462890625,
      "loss": 0.082,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4397966861724854,
      "rewards/margins": 6.578917026519775,
      "rewards/rejected": -5.139120101928711,
      "step": 80
    },
    {
      "epoch": 0.9481481481481482,
      "eval_logits/chosen": -1.2124426364898682,
      "eval_logits/rejected": -1.2046594619750977,
      "eval_logps/chosen": -254.75619506835938,
      "eval_logps/rejected": -231.60377502441406,
      "eval_loss": 0.0038307614158838987,
      "eval_rewards/accuracies": 1.0,
      "eval_rewards/chosen": 1.505155086517334,
      "eval_rewards/margins": 7.442600727081299,
      "eval_rewards/rejected": -5.937446117401123,
      "eval_runtime": 32.689,
      "eval_samples_per_second": 9.177,
      "eval_steps_per_second": 4.589,
      "step": 80
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4884653389453888,
      "learning_rate": 2.771144194993564e-06,
      "logits/chosen": -1.2416605949401855,
      "logits/rejected": -1.2296816110610962,
      "logps/chosen": -249.30091857910156,
      "logps/rejected": -233.485107421875,
      "loss": 0.0592,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4853969812393188,
      "rewards/margins": 7.343912124633789,
      "rewards/rejected": -5.858516216278076,
      "step": 85
    },
    {
      "epoch": 1.0592592592592593,
      "grad_norm": 0.7659801244735718,
      "learning_rate": 2.5246976537036646e-06,
      "logits/chosen": -1.2468934059143066,
      "logits/rejected": -1.2286638021469116,
      "logps/chosen": -246.8239288330078,
      "logps/rejected": -250.5310821533203,
      "loss": 0.0724,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.4561851024627686,
      "rewards/margins": 7.865111351013184,
      "rewards/rejected": -6.408926486968994,
      "step": 90
    },
    {
      "epoch": 1.1185185185185185,
      "grad_norm": 0.38793888688087463,
      "learning_rate": 2.278010261692663e-06,
      "logits/chosen": -1.2983732223510742,
      "logits/rejected": -1.2804615497589111,
      "logps/chosen": -252.77978515625,
      "logps/rejected": -252.32693481445312,
      "loss": 0.0191,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5053364038467407,
      "rewards/margins": 8.432610511779785,
      "rewards/rejected": -6.927272796630859,
      "step": 95
    },
    {
      "epoch": 1.1777777777777778,
      "grad_norm": 0.26041483879089355,
      "learning_rate": 2.0334877064386277e-06,
      "logits/chosen": -1.3262513875961304,
      "logits/rejected": -1.3371670246124268,
      "logps/chosen": -245.1876220703125,
      "logps/rejected": -246.6241912841797,
      "loss": 0.0448,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.578916311264038,
      "rewards/margins": 8.699419021606445,
      "rewards/rejected": -7.120502471923828,
      "step": 100
    },
    {
      "epoch": 1.237037037037037,
      "grad_norm": 0.6527349948883057,
      "learning_rate": 1.793514564001503e-06,
      "logits/chosen": -1.3657090663909912,
      "logits/rejected": -1.2651013135910034,
      "logps/chosen": -244.61257934570312,
      "logps/rejected": -254.30758666992188,
      "loss": 0.0112,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6488502025604248,
      "rewards/margins": 9.130093574523926,
      "rewards/rejected": -7.481243133544922,
      "step": 105
    },
    {
      "epoch": 1.2962962962962963,
      "grad_norm": 2.1632845401763916,
      "learning_rate": 1.5604310447144052e-06,
      "logits/chosen": -1.3299405574798584,
      "logits/rejected": -1.2872850894927979,
      "logps/chosen": -245.3091583251953,
      "logps/rejected": -255.490966796875,
      "loss": 0.0261,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6974436044692993,
      "rewards/margins": 9.366186141967773,
      "rewards/rejected": -7.6687445640563965,
      "step": 110
    },
    {
      "epoch": 1.3555555555555556,
      "grad_norm": 0.1286105066537857,
      "learning_rate": 1.3365101715280473e-06,
      "logits/chosen": -1.3437144756317139,
      "logits/rejected": -1.308386206626892,
      "logps/chosen": -253.9674072265625,
      "logps/rejected": -272.49365234375,
      "loss": 0.0223,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6393362283706665,
      "rewards/margins": 9.668588638305664,
      "rewards/rejected": -8.029253005981445,
      "step": 115
    },
    {
      "epoch": 1.4148148148148147,
      "grad_norm": 0.19932617247104645,
      "learning_rate": 1.1239356135643544e-06,
      "logits/chosen": -1.4373385906219482,
      "logits/rejected": -1.311806082725525,
      "logps/chosen": -238.94869995117188,
      "logps/rejected": -255.07223510742188,
      "loss": 0.0361,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6996066570281982,
      "rewards/margins": 9.449872970581055,
      "rewards/rejected": -7.750267028808594,
      "step": 120
    },
    {
      "epoch": 1.4148148148148147,
      "eval_logits/chosen": -1.3373111486434937,
      "eval_logits/rejected": -1.3620884418487549,
      "eval_logps/chosen": -253.48770141601562,
      "eval_logps/rejected": -254.48934936523438,
      "eval_loss": 0.0013274748343974352,
      "eval_rewards/accuracies": 1.0,
      "eval_rewards/chosen": 1.6320068836212158,
      "eval_rewards/margins": 9.85800838470459,
      "eval_rewards/rejected": -8.226000785827637,
      "eval_runtime": 32.7807,
      "eval_samples_per_second": 9.152,
      "eval_steps_per_second": 4.576,
      "step": 120
    },
    {
      "epoch": 1.474074074074074,
      "grad_norm": 0.18961356580257416,
      "learning_rate": 9.247803910457226e-07,
      "logits/chosen": -1.4020360708236694,
      "logits/rejected": -1.3363269567489624,
      "logps/chosen": -261.16888427734375,
      "logps/rejected": -268.37469482421875,
      "loss": 0.0078,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6476818323135376,
      "rewards/margins": 9.694053649902344,
      "rewards/rejected": -8.046372413635254,
      "step": 125
    },
    {
      "epoch": 1.5333333333333332,
      "grad_norm": 1.7179895639419556,
      "learning_rate": 7.409866592687768e-07,
      "logits/chosen": -1.319007396697998,
      "logits/rejected": -1.3562268018722534,
      "logps/chosen": -255.4982452392578,
      "logps/rejected": -269.7880859375,
      "loss": 0.0203,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5472588539123535,
      "rewards/margins": 9.534708023071289,
      "rewards/rejected": -7.987447261810303,
      "step": 130
    },
    {
      "epoch": 1.5925925925925926,
      "grad_norm": 0.08707338571548462,
      "learning_rate": 5.743467687686563e-07,
      "logits/chosen": -1.3817211389541626,
      "logits/rejected": -1.37587571144104,
      "logps/chosen": -232.6337432861328,
      "logps/rejected": -252.2570037841797,
      "loss": 0.0037,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.632702112197876,
      "rewards/margins": 10.254966735839844,
      "rewards/rejected": -8.62226390838623,
      "step": 135
    },
    {
      "epoch": 1.651851851851852,
      "grad_norm": 0.13967636227607727,
      "learning_rate": 4.264857863744956e-07,
      "logits/chosen": -1.3792521953582764,
      "logits/rejected": -1.4125159978866577,
      "logps/chosen": -244.64794921875,
      "logps/rejected": -263.6951599121094,
      "loss": 0.0065,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6426550149917603,
      "rewards/margins": 10.274374008178711,
      "rewards/rejected": -8.631717681884766,
      "step": 140
    },
    {
      "epoch": 1.7111111111111112,
      "grad_norm": 0.2651829123497009,
      "learning_rate": 2.9884564761020083e-07,
      "logits/chosen": -1.4046602249145508,
      "logits/rejected": -1.306209683418274,
      "logps/chosen": -253.60055541992188,
      "logps/rejected": -268.1448669433594,
      "loss": 0.024,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6391242742538452,
      "rewards/margins": 9.817241668701172,
      "rewards/rejected": -8.178117752075195,
      "step": 145
    },
    {
      "epoch": 1.7703703703703704,
      "grad_norm": 0.35149699449539185,
      "learning_rate": 1.9267109498579962e-07,
      "logits/chosen": -1.371178388595581,
      "logits/rejected": -1.3743144273757935,
      "logps/chosen": -254.23898315429688,
      "logps/rejected": -275.0663757324219,
      "loss": 0.0069,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.7041237354278564,
      "rewards/margins": 10.133057594299316,
      "rewards/rejected": -8.428934097290039,
      "step": 150
    },
    {
      "epoch": 1.8296296296296295,
      "grad_norm": 0.17708095908164978,
      "learning_rate": 1.0899753930869395e-07,
      "logits/chosen": -1.3239552974700928,
      "logits/rejected": -1.2965762615203857,
      "logps/chosen": -248.94046020507812,
      "logps/rejected": -263.2754821777344,
      "loss": 0.0098,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.6565126180648804,
      "rewards/margins": 10.058399200439453,
      "rewards/rejected": -8.401885986328125,
      "step": 155
    },
    {
      "epoch": 1.8888888888888888,
      "grad_norm": 0.4618660807609558,
      "learning_rate": 4.864096239091287e-08,
      "logits/chosen": -1.3736923933029175,
      "logits/rejected": -1.3072559833526611,
      "logps/chosen": -248.0514373779297,
      "logps/rejected": -260.2343444824219,
      "loss": 0.0076,
      "rewards/accuracies": 1.0,
      "rewards/chosen": 1.5864439010620117,
      "rewards/margins": 9.794657707214355,
      "rewards/rejected": -8.208213806152344,
      "step": 160
    },
    {
      "epoch": 1.8888888888888888,
      "eval_logits/chosen": -1.357016921043396,
      "eval_logits/rejected": -1.3859326839447021,
      "eval_logps/chosen": -253.38064575195312,
      "eval_logps/rejected": -257.8994140625,
      "eval_loss": 0.0011594027746468782,
      "eval_rewards/accuracies": 1.0,
      "eval_rewards/chosen": 1.6427093744277954,
      "eval_rewards/margins": 10.209718704223633,
      "eval_rewards/rejected": -8.567008972167969,
      "eval_runtime": 32.9831,
      "eval_samples_per_second": 9.096,
      "eval_steps_per_second": 4.548,
      "step": 160
    }
  ],
  "logging_steps": 5,
  "max_steps": 168,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 20,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
